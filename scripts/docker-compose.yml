version: '3'

services:
  ai-detection-service:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    environment:
      - TRANSFORMERS_CACHE=/app/model_cache
    deploy:
      resources:
        limits:
          memory: 4G  # Adjust based on your server resources
    restart: unless-stopped 